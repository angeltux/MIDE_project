---
title: "Regresion MIDE"
author: "Livia Sánchez Carrasco"
date: "Febrero 2022"
output:
  html_document:
    toc: yes
    toc_float: yes
    theme: cerulean
    highlight: kate
    fig_width: 7
    fig_height: 6
    fig_caption: yes
  pdf_document:
    toc: yes
editor_options:
  chunk_output_type: console
---

```{r setup, include=FALSE, message=FALSE, warning=FALSE}
knitr::opts_chunk$set(echo = TRUE)
#Cargamos las librerias
library(tidyverse)
library(ggplot2)
#install.packages("ggsci")
library(ggpubr)
library(GGally)
library(ggsci)
```

## Ejercicios Análisis de Regresión 
### Ejercicio 4

**Trabajo de investigación: Cada equipo debe de buscar un conjunto de datos, ajustar un modelo y hacer un estudio de diagnóstico para determinar cuál es el mejor modelo que se puede ajustar a sus datos. Su estudio no debe de ser mayor a 3 cuartillas. El estudio que les propongo lo pueden hacer según su criterio. Dependiendo de la calidad del estudio y de lo conciso pero eficientes que sean, será como se evaluará esta última pregunta.**

Para este ejercicio empleamos la BD de Stroke prediction, la cual se encuentra en kaggle en la siguiente liga: https://www.kaggle.com/fedesoriano/stroke-prediction-dataset

La BD consta de 5110 observaciones y 12 atributos, los cuales son:

id: Identificación unica de cada observación.  
gender: Genero de los participantes.  
age: Edad de los participantes va de 0.08 a 82 años
hypertension: Variable binaria que indica si las personas tienen o no hipertensión.  
hear_disease: Variable binaria que indica si las personas tienen o no enfermedades cardiacas.
ever_married: Variable booleana que indica si la persona se ha casado alguna vez.
work_type: Tipo del trabajo del paciente, que incluye: Privado, Autoempleado, Gobierno, entre otros.  
avg_glucose_level: Promedio de glucosa en la sangre.
bmi: Indice de masa corporal
smoking_status: Estatus de fumador del paciente
Stroke_event: Variable binaria que indica si ha tenido infartos o no.

Importamos los datos y realizamos un análisis descriptivo.

```{r Descriptiva Stroke, echo=FALSE, message=FALSE, warning=FALSE}
path <- "C:\\Users\\afmar\\OneDrive\\Documentos\\Diplomado_MIDE\\Final\\strokedata.csv"
stroke <- read_csv(path)
#getwd()



head(stroke,30)

stroke <- stroke [,c(12,1,3,9,10,2,4,5,6,7,8,11)]
stroke$bmi[stroke$bmi == "N/A"] <- "" 
stroke$bmi <- as.numeric(stroke$bmi)
stroke$gender <- as.factor(stroke$gender)
stroke$hypertension <- as.factor(stroke$hypertension)
stroke$heart_disease <- as.factor(stroke$heart_disease)
stroke$ever_married <- as.factor(stroke$ever_married)
stroke$work_type <- as.factor(stroke$work_type)
stroke$Residence_type <- as.factor(stroke$Residence_type)
stroke$stroke <- as.factor(stroke$stroke)
stroke$smoking_status <- as.factor(stroke$smoking_status)



library(psych)
descri <- stroke %>%
           describe () 


descri <- descri %>% 
           filter(row_number() == 3|
                  row_number() == 9|
                  row_number() == 10)

descri

```

La estadistica descriptiva de las variables continuas muestra que la media de la variable edad es 43.23, con un rango que va de 0.08 meses a 82 años. Observamos que la distribución puede considerarse simétrica y platocurtica. En cuanto al nivel promedio de glucosa la media es de 106.15, con un rango de 55.12 a 271.74, en este caso la distribución está sesgada a la derecha y es leptocurtica. Finalmente, la media del bmi es de 172.19, con un rango de 1 hasta 419, ducga dustribución está sesgada positivamente y cercana a una distribución leptocuritca.  

```{r Graficas Univariadas, echo=FALSE, message=FALSE, warning=FALSE}

genero<-stroke %>%
         count(gender) 
g6.1<- ggbarplot(genero, "gender", "n", fill = "gender")

hyp<-stroke %>%
         count(hypertension) 
g6.2<- ggbarplot(hyp, "hypertension", "n", fill = "hypertension")

heart<-stroke %>%
         count(heart_disease) 
g6.3<- ggbarplot(heart, "heart_disease", "n", fill = "heart_disease")
married<-stroke %>%
         count(ever_married) 
g6.4<- ggbarplot(married, "ever_married", "n", fill = "ever_married")
smoke<-stroke %>%
         count(smoking_status) 
g6.5<- ggbarplot(smoke, "smoking_status", "n", fill = "smoking_status")
stroken<-stroke %>%
         count(stroke) 
g6.6<- ggbarplot(stroken, "stroke", "n", fill = "stroke")

ggarrange(g6.1,g6.2,g6.3,g6.4,g6.5,g6.6, ncol=2, nrow=3)



```

Observamos que la BD esta conformada por 2994 mujeres y 2115 hombre, y un paciente identificado como otro. Asimismo, vemos que de los 5110 pacientes solo 498 tienen hipertensión y 276 tienen una enfermedad cardíaca. En cuanto al estado civil de los pacientes vemos que 1757 no están casados y 3353 si lo están. Se observa que 885 de los pacientes fumaban anteriormente, 1892 nunca han fumado, 789 fuma y 1544 no proporcionó información. Finalmente, vemos que 4861 pacientes no ha tenido infartos, mientras 249 sí. 

```{r Graficas bivariadas I, echo=FALSE, message=FALSE, warning=FALSE}

g7 <- ggpairs (stroke, columns = 3:5, ggplot2::aes(colour = as.factor(stroke), alpha = 0.4))
g7 <- g7 + scale_fill_simpsons() + scale_color_simpsons()
g7
```

Los análisis de correlaciones muestran un nivel bajo de correlación entre las variables, se observa que la media de edad de las personas que han tenido un infarto está sesgada a la derecha, mientras que la distribución de las personas que no han tenido infartos es mas homogénea a lo largo de la edad. Sin embargo, la densidad de personas sin infartos tiende a disminuir después de los 60 años. Mientras que es más común tener un infarto después de los 70 años. También podemos observar que la media del indice de masa corporal y el nivel de glucosa promedio es similar entre aquellos que han tenido infartos, como para aquellos que no los han tenido. Sin embargo, es interesante notar que las personas con un nivel de glucosa promedio de entre 200 y 225 parecen aumentar el número de infartos.

```{r Graficas bivariadas II, echo=FALSE, message=FALSE, warning=FALSE}

g7.1 <- ggpairs (stroke, columns = 3:5, ggplot2::aes(colour = as.factor(Residence_type), alpha = 0.4))
g7.1 <- g7.1 + scale_fill_simpsons() + scale_color_simpsons()
g7.1

g7.2 <- ggpairs (stroke, columns = 3:5, ggplot2::aes(colour = as.factor(work_type), alpha = 0.4))
g7.2 <- g7.2 + scale_fill_simpsons() + scale_color_simpsons()
g7.2

```

Al analizar los datos considerando el lugar de residencia de las personas observamos que las variables edad, promedio de nivel de glucosa y bmi se distribuyen de forma similar en áreas rurales y urbanas. Al analizar las variables por tipo de trabajo observamos que no los menores de edad tipicamente tiene trabajo de niños o nunca han trabajado. Después de los 20 años no se observan diferencia entre los tipos de trabajo de los pacientes. Tampoco se observa que el promedio de glucosa promedio sea diferente entre tipos de trabajo. Finalmente, se observa que las personas con un autoempleo o que trabajan en la iniciativa privada tienen el mayor bmi. 

```{r Graficas bivariadas III, echo=FALSE, message=FALSE, warning=FALSE}

g7.3 <- ggpairs (stroke, columns = 3:5, ggplot2::aes(colour = as.factor(smoking_status), alpha = 0.4))
g7.3 <- g7.3 + scale_fill_simpsons() + scale_color_simpsons()
g7.3
```

Finalmente cuando se evalúan los datos por el estatus de fumador observamos que los que no proporcionaron información son los menores de edad, que la distribución de no fumadores es homogenea a lo largo de diferentes edades, que la prevalencia de los ex-fumadores aumenta despues de los 50 años y que la mayor prevalencia de los fumadores es entre los 40 y 50 años. El estatus de fumador no parece afectar el nivel de glucosa promedio en la sangre, y solo se ve que los que nunca han fumado tienen bmi menor, probablemente porque corresponde a menores de edad. Igual que en los casos anteriores la correlación global entre estas variables es baja.

A fin de evaluar el papel de las variables analizadas en la probabilidad de tener un infarto se implementaron cuatro modelos. El primer modelo considera como predictor unicamente a la edad. El segundo modelo considera aquellas variable consideradas como biológicas (i.e. edad, nivel de sucrosa promedio, bmi, genero, hipertensión y enfermedades cardiacas). El segundo modelo analiza la contribución del estatus de fumador y finalmente el cuarto modelo considera las variables sociales (i.e. Casado alguna vez, tipo de trabajo y tipo de residencia). Es importante señalar que cada modelo nuevo se construyo añadiendo las variables señalads al modelo previo. 

```{r Modelo 4, echo=FALSE, message=FALSE, warning=FALSE}
#Modelo basal sin predictores
modelo4.0 <- glm(stroke ~ age, data = stroke, family = binomial(link="logit") )
#Modelo con variables biologicas como predictores
modelo4.1 <- glm(stroke ~ age + avg_glucose_level + bmi + gender + hypertension + heart_disease, data = stroke, family = binomial(link="logit"))
#Modelo considerando el estatus de fumador
modelo4.2 <- glm(stroke ~ age + avg_glucose_level + bmi + gender + hypertension + heart_disease+smoking_status, data = stroke, family = binomial)
#Modelo considerando las variables sociales
modelo4.3 <- glm(stroke ~ age + avg_glucose_level + bmi + gender + hypertension + heart_disease+smoking_status+ever_married + work_type + Residence_type, data = stroke, family = binomial)

summary(modelo4.0)
summary(modelo4.1)
summary(modelo4.2)
summary(modelo4.3)

#Comparamos el modelo 4.0 con el 4.1
modelChi1 <- modelo4.0$deviance - modelo4.1$deviance
chidf1 <- modelo4.0$df.residual - modelo4.1$df.residual
chisq.prob1 <- 1 - pchisq(modelChi1, chidf1)
modelChi1; chidf1; chisq.prob1

#Comparamos el modelo 4.1 con el 4.2
modelChi2 <- modelo4.1$deviance - modelo4.2$deviance
chidf2 <- modelo4.1$df.residual - modelo4.2$df.residual
chisq.prob2 <- 1 - pchisq(modelChi2, chidf2)
modelChi2; chidf2; chisq.prob2


#Comparamos el modelo 4.2 con el 4.3
modelChi3 <- modelo4.2$deviance - modelo4.3$deviance
chidf3 <- modelo4.2$df.residual - modelo4.3$df.residual
chisq.prob3 <- 1 - pchisq(modelChi3, chidf3)
modelChi3; chidf3; chisq.prob3

```

El AIC para el modelo basal que solo considera como predictor la edad es de 1620.3, el estimado para la variable edad es de 0.075 y es significativo con un nivel de significancia menor a 0.001. En el segundo modelo el AIC es de 1390.5 y las variables significativas fueron el nivel promedio de glucosa, el bmi, tener hipertensión y enfermedades cardíacas. Para el segundo modelo que considera el estatus de fumador el valor de AIC es de 1391.4 y ninguno de los niveles de esta variable es significativo. Finalmente, para el modelo que añade las variables sociales el valor del AIC es de 1397.2 y no se observa un efecto significativo de los niveles de las variables asociadas con cuestiones sociales. Consideramos los valores de AIC podemos concluir que el mejor modelo es aquel que solo considera las variables biológicas, esto fue confirmado por una prueba $\chi^2$ de la devianza, que al comparar el modelo basal con el modelo 1 $\chi^2$ (207) = 241.713, el cual es significativo al 0.05. Al comparar el modelo 1 con el modelo 2 obtenemos una $\chi^2$ (3) = 5.1614, p > 0.5. Así los coeficientes del modelo final son:

```{r final, echo =FALSE, message=FALSE, warning=FALSE}
modelo4.1$coefficients


predict4 <- predict(modelo4.1, type = "response")


clses.predict4 <- ifelse(predict4 > 0.5, "1", "0")





stroke2 <- stroke %>% 
                  filter(bmi != "") %>%
                  select(age, avg_glucose_level, bmi)
id <- colnames(stroke2)

stroke2 <- stroke2 %>%
         mutate(logit = log(predict4/(1-predict4))) %>%
         gather(key = "id", value = "predict.v", -logit)

ggplot(stroke2, aes(logit, predict.v))+
  geom_point(size = 0.5, alpha = 0.5) +
  theme_bw() + 
  facet_wrap(~id, scales = "free_y")

library(car)
print("Para determinar la multicolinealidad: ")
vif(modelo4.1)

#Realizamos la detección de datos influenciales o extremos
#Ahora realizamos el análisis de los residuos Studentizados para determinar si hay puntos outliers
sig4 <- qt(.975,4908-7-2)
stud4<-rstudent(modelo4.1)
outliers4 <- stud4 [stud4 > sig4 | stud4 < -sig4]
print("Los datos outliers son: ")
outliers4
length(outliers4)

stroke3 <- stroke %>% 
                  filter(bmi != "") %>%
                  select(stroke)

#Ahora realizamos el análisis de Cook para determinar si hay puntos influenciales
cook_d4 <- cooks.distance(modelo4.1)
influential4 <- cook_d4[cook_d4 > 1]
print("Los datos influeciales son: ")
influential4

plot(modelo4.1, which = 4, id.n = 5)

outlier <- stroke %>% 
         filter(id != 44831) %>%
         select(stroke, age, avg_glucose_level, bmi, gender, hypertension, heart_disease)

modelo4.SO <- glm(stroke ~ age + avg_glucose_level + bmi + gender + hypertension + heart_disease, data = outlier, family = binomial(link="logit"))

summary(modelo4.SO)


####################################################################

```
### Red Neuronal

El siguiente analisis consta en comparar la regresion anterior mediante el uso de una red neuronal basada en 3 entradas conformadas por las variables predictoras y 1 una sola capa oculta, utilizando como funciones de activacion "Relu y Sigmoide.


Preparamos los datos a utilizar en el modelo de la Red Neuronal tomando como base el Modelo 4.1 "Modelo con variables biologicas como predictores".
```{r NN Modelo 4.1, echo=FALSE, message=FALSE, warning=FALSE}


##################Neural Network##################################################

#Cargamos las librerias

library(tidyverse)
library(keras)
library(tensorflow)
library(caret)
theme_set(theme_minimal())
#library(recipes)



 # encode_ordinal <- function(x, order = unique(x)) {
 #   x <- as.numeric(factor(x, levels = order, exclude = NULL))
 #   x
 # }






#stroke1 <- read_csv(choose.files())

stroke1 <- stroke


#stroke1$bmi[stroke1$bmi == "N/A"] <- ""
#stroke1$bmi <- as.numeric(stroke1$bmi)

#mean(stroke1[!(is.na(stroke1$bmi)), ]$bmi)
 
 stroke1$bmi[is.na(stroke1$bmi)] <- 28
 
 

 #stroke1$smoking_status <- encode_ordinal(stroke1[["smoking_status"]])
 #stroke1$gender <- encode_ordinal(stroke1[["gender"]])
 #stroke1$hypertension <- encode_ordinal(stroke1[["hypertension"]])
 #stroke1$heart_disease <- encode_ordinal(stroke1[["heart_disease"]])
 #stroke1$ever_married <- encode_ordinal(stroke1[["ever_married"]])
 #stroke1$work_type <- encode_ordinal(stroke1[["work_type"]])
 #stroke1$Residence_type <- encode_ordinal(stroke1[["Residence_type"]])
 
 #stroke1$stroke <- as.factor(stroke1$stroke)
 
 #stroke1 <- stroke1[ -c(1) ]
 
 #stroke1 <- stroke1[ -c(1,6,7,8,11) ]
 
 stroke1 <- stroke1[ c(1,3,4,5) ]


#datos 
head(stroke1,20)





```
Ahora definimos nuestro conjunto de datos de entrenamiento y prueba que se habra de escalar, de esta manera se reducira la magnitud de los valores, de modo que la Red Neuronal pueda realizar la propagacion correcta entre las neuronas de la capas ocultas y actualizara los pesos de las unidades. 

```{r NN Modelo 4.1 Trn Tst, echo=FALSE, message=FALSE, warning=FALSE}

# particionamos los datos
n <- nrow(stroke1)
set.seed(1200)
n_test <- ceiling(n/3)
idTst <- sample(1:n, n_test)
#idTst <- sample(1:n, 4909) # 4909 - 201

stroke1_train <- stroke1[-idTst,]
stroke1_train <- head(stroke1_train,200)
#stroke1_test <-stroke1[ idTst,]


library(neuralnet)



nn=neuralnet(stroke~.,data = stroke1_train,hidden = c(10,2),act.fct = "logistic",threshold = 0.4)



plot(nn,rep = "best")


# Seleccionamos las variables explicativas Training y Testing

XTrn <- dplyr::select(stroke1[-idTst,],-c("stroke"))
XTst <- dplyr::select(stroke1[ idTst,],-c("stroke"))


#model_recipe <- recipe(stroke ~.,data = stroke1_train)%>%
#prep(data = stroke1_train)

#summary(model_recipe)


# Predictors
#XTrn <- bake(model_recipe, new_data = stroke1_train) %>% select(-stroke)
#XTst  <- bake(model_recipe, new_data = stroke1_test) %>% select(-stroke)


head(XTrn,20)
head(XTst,20)           


# Estandarizamos las covariables
medias <- apply(XTrn, 2, mean)
desv_std <- apply(XTrn, 2, sd)

XTrn <- scale(XTrn, center = medias, scale = desv_std)
XTst <- scale(XTst, center = medias, scale = desv_std)

head(XTrn,20)
head(XTst,20)

dim(XTrn)
dim(XTst)



## Definimos la variable respuesta
yTrn <- to_categorical(stroke1$stroke[-idTst])
yTst <- to_categorical(stroke1$stroke[ idTst])

dim(yTrn)
dim(yTst)

```

El modelo que se esta creando es un modelo secuencial y para esto necesitamos suministrar la cantidad inicial de neuronas que consta de 10 unidades para la capa de entrada, despues agregamos una capa oculta con 2 unidades mas para finalmente crear una capa de salida para precedir la variable Stroke.
```{r NN Modelo 4.1 fit, echo=FALSE, message=FALSE, warning=FALSE}



## Construimos nuestro modelo de red Neuronal

# model <- keras_model_sequential() %>%
#   layer_dense(units = 25, activation = 'sigmoid',
#               input_shape = ncol(XTrn)) %>%
#   layer_dense(units = 25, activation = 'sigmoid') %>%
#   layer_dense(units = 20, activation = 'sigmoid')

# model <- keras_model_sequential() %>% 
#    layer_dense(units=64, activation="relu", input_shape=ncol(XTrn)) %>% 
#    layer_dense(units=32, activation = "relu") %>% 
#    layer_dense(units=1, activation="linear")

#1 model <- keras_model_sequential() %>% 
#     layer_dense(units = 200, activation = "relu", input_shape = ncol(XTrn)) %>%
#     layer_dense(units = 100, activation = "relu") %>%
#     layer_dense(units = 100, activation = "relu") %>%
#     layer_dense(units = 50, activation = "relu") %>%
#     layer_dense(units = 2, activation = "softmax")

  #2 model <- keras_model_sequential() %>% 
  #    layer_dense(units = 64, activation = "relu", input_shape = ncol(XTrn)) %>%
  #    layer_dense(units = 64, activation = "relu") %>%
  #    layer_dense(units = 32, activation = "relu") %>%
  #    layer_dense(units = 20, activation = "relu") %>%
  #    layer_dense(units = 2, activation = "softmax")
  
    # model <- keras_model_sequential() %>% 
    #    layer_dense(units = 64, activation = "relu", input_shape = ncol(XTrn)) %>%
    #    layer_dense(units = 64, activation = "relu") %>%
    #    layer_dense(units = 32, activation = "relu") %>%
    #    layer_dense(units = 20, activation = "relu") %>%
    #    layer_dense(units = 2, activation = "softmax")
    
  
      # model <- keras_model_sequential() %>% 
      #  layer_dense(units = 64, activation = "relu", input_shape = ncol(XTrn)) %>%
      #  layer_dense(units = 64, activation = "relu")%>%
      #  layer_dense(units = 1)
      # 

       
      model <- keras_model_sequential() %>% #1.0
       layer_dense(units = 10, activation = "relu", input_shape = ncol(XTrn)) %>%
       layer_dense(units = 2, activation = "relu")%>%
       layer_dense(units = 1)


       summary(model)
      
       model %>% compile(  #1.0
   loss='mse',optimizer='rmsprop',metrics='mse')
       
       history <- model %>% fit( #1.0
  XTrn, yTrn, 
  epochs = 35,
  batch_size = 8,
  #validation_data = list(XTst, yTst)
  #validation_split = 0.7, shuffle = T
  validation_split = 0.30
)
       
       
    
#       
#       model <- keras_model_sequential() %>%   #2.0
#        layer_dense(units = 16, activation = "sigmoid", input_shape = ncol(XTrn)) %>%
#        layer_dense(units = 16, activation = "relu")%>%
#        layer_dense(units = 1)
#        
#       
#       model %>% compile(  optimizer = 'adam',  #2.0
#     loss      = 'binary_crossentropy',
#     #loss      = 'categorical_crossentropy',
#     metrics   = c('accuracy'))
#      
#   
#       history <- model %>% fit( #2.0
#   XTrn, yTrn,
#   epochs = 35,
#   batch_size = 50,
#   validation_split = 0.30
# )
#       
      
      
      

     # model %>% compile(
     #   optimizer = optimizer_rmsprop(learning_rate = 0.001), #"rmsprop",
     #    #optimizer = "rmsprop", 
     #   loss = 'categorical_crossentropy',
     #   metric = c("accuracy")
     # )
# 


#model %>% compile(
 # loss='binary_crossentropy',optimizer='adam',metrics=c('accuracy'))






  # # Network config
  #  model %>% compile(
  #  loss = 'binary_crossentropy',
  #  optimizer = 'adam',
  #  metrics = c('accuracy')
  # )
   
 #  
 # # Running our data
 # history <-model %>% fit(
 #  XTrn, yTrn, 
 #  epochs = 50, 
 #  batch_size = 5,
 #  validation_split = 0.3
 # )


#history

plot(history)
```
 
 Finalmente evaluamos el modelo con la informacion de prueba y generamos la comparativa respecto al modelo GLM.
```{r NN Modelo 4.1 Prediction, echo=FALSE, message=FALSE, warning=FALSE}

pred <- predict(model, XTst)
test_y <- stroke1[ idTst,]  %>% select(stroke)%>% as.matrix()

#pred

#final <- data.frame(preds_nn=pred,preds_lr=predict4,test_y)

final <- data.frame(preds_nn=pred,test_y )


head(final,30)








```

